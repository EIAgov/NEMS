# -*- coding: utf-8 -*-
"""
@author: MC6 (Mike Cole)

This package includes functions for reading a NEMS RAN file, which is a binary
version of a NEMS report. RAN files are used as inputs to GrafNEM, but they
also include all report items that might be generated by ftab.

Dan Skelly provided a detailed description of the binary RAN file structure, 
which is available in a separate document. That info was vital in writing the
code in the package,

Reading a binary file in Python:
  https://docs.scipy.org/doc/numpy/user/basics.rec.html
  https://docs.python.org/3/library/struct.html#examples

Relationship between the NEMS RAN report and the NEMS XML report
Every NEMS run generates an XML report in addition to a RAN file. The XML 
report includes only those tables specified in a input file ???, but additional
tables can be created after a run via the NEMS utility ftab.

Example NEMS XML file:
    \\nem1\K\output\aeo2019\ref2019\d102218a\ref2019.1022a.xml

Column A of the XML report has unique table/row identifiers (uid). This column
is normally hidden. To unhide column A, see the instructions at 

    https://support.office.com/en-us/article/unhide-the-first-column-or-row-
    in-a-worksheet-d6b47608-80ee-4021-9b51-6a1f57269ec9

How to use this package from a Python console:
    sys.path.append('//nem6/d/users/mc6/spyderproj/ranfile')
    import read_ranfile as r
    reload(r)
    ranfile = r'\\nem3\M\ogs\mc6\RAN\testdef.0829a.RAN'
    t, x = r.process_ran_file_to_dicts(ranfile, logfile)

t and x are dictionaries of dictionaries.

t.keys() = 6-character table IDs, same as in XML except:
    * ‘A’ as 4th character in t.keys() maps to ‘0’ as 4th character in the XML 
    file (e.g., SUPA00 in t.keys() corresponds to SUP000 in the XML file)
    * t.keys() includes regional tables (e.g., AUAA01) and other tables that 
    might not be shown in the XML report

t[<table id>].keys() = [‘tablenum’, ‘caption’, ‘caption_sub’, ‘units’]

x.keys() = 6-character table IDs, the same as t.keys() except for some blank/empty items:
    * [i for i in x.keys() if i not in t.keys()] = ['QUA000']
    * [i for i in t.keys() if i not in x.keys()] = ['D45A00', 'B23A00']

x[<table id>].keys() = list of row IDs (length varies)
    * x['TSTA06'].keys() = [‘la_PercentageTotalA’, ‘mh_FuelCell, …]

x[<table id>][<row id>].keys() = ['uid', 'table', 'row', 'tablenum', 'rownum', 'data', 'text']
    * x[<table id>][<row id>]['uid'] = <table id>:<row id>
    * x[<table id>][<row id>]['table'] = <table id>
    * x[<table id>][<row id>]['row'] = <row id>
    * x[<table id>][<row id>]['tablenum’] = table number
    * x[<table id>][<row id>]['rownum’] = row number
    * x[<table id>][<row id>]['data'] = Pandas data series
    * x[<table id>][<row id>]['text'] = a dictionary with keys:
        * ['sector','data_type','graph_label','energy_source','graph_units', 
        'var_units','expression','geography']

Example of x[<table id>][<row id>]['text']:

x['SUPA00']['ba_CrudeOilLease'][‘text’]: 

{'data_type': 'supply|production',
 'energy_source': 'crude oil and lease condensate|',
 'expression': 'T1(1,IY,IS)=RFQTDCRD(15,IY)*RDAYS*CFCRDDOM(IY)*.001',
 'geography': 'united states',
 'graph_label': 'Total Energy : Production : Crude Oil and Lease Condensate',
 'graph_units': 'quads',
 'sector': 'total energy|',
 'var_units': ''}
"""
import numpy as np
import struct
import pandas as pd
from datetime import datetime
import collections


def read_datatype_1(data, ByteLoc):
    """ Table: main heading
    """
    RGTLen = struct.unpack('h', data[ByteLoc + 20: ByteLoc + 22])[0]

    dt=[('RGTNum','i2'),
        ('RGTKey','S6'),
        ('RGTAct','i2'),
        ('RGTReg','i2'),
        ('RGTTyp','i2'),
        ('RGForm','S6'),
        ('RGTLen','i2'),
        ('RGText','S'+str(RGTLen))]

    d = np.frombuffer(data[ByteLoc:ByteLoc+22+RGTLen], np.dtype(dt))[0]
    datatype_header = {j[0]: d[i] for i, j in enumerate(dt)}
    return datatype_header


def read_datatype_2(data, ByteLoc):
    """ Table: subheading
    """
    RGTLen = struct.unpack('h', data[ByteLoc + 34: ByteLoc + 36])[0]

    dt=[('RGTNum','i2'),
        ('RGTKey','S6'),
        ('RGRNum','i2'),
        ('RGRKey','S16'),
        ('RGTTyp','i2'),
        ('RGForm','S6'),
        ('RGTLen','i2'),
        ('RGText','S'+str(RGTLen))]

    d = data[ByteLoc:ByteLoc+36+RGTLen]
    d = np.frombuffer(d, np.dtype(dt))[0]
    return d


def read_datatype_3(data, ByteLoc):
    """ Table: yearly data for a single row
    """
    z = {}

    RGTLen = struct.unpack('h', data[ByteLoc + 34: ByteLoc + 36])[0]

    dt=[('RGTNum','i2'),
        ('RGTKey','S6'),
        ('RGRNum','i2'),
        ('RGRKey','S16'),
        ('RGTTyp','i2'),
        ('RGForm','S6'),
        ('RGTLen','i2'),
        ('RGText','S'+str(RGTLen)),
        ('RGDTyp', 'i2'),
        ('RGDFYr', 'i2'),
        ('RGDLYr', 'i2')]

    d = data[ByteLoc:ByteLoc+36+RGTLen+6]
    d = np.frombuffer(d, np.dtype(dt))[0]
    data_header = {j[0]: d[i] for i, j in enumerate(dt)}

    z['tablenum'] = data_header['RGTNum']
    z['rownum'] = data_header['RGRNum']

    z['table'] = data_header['RGTKey'].decode('utf-8')
    z['row'] = data_header['RGRKey'].strip().decode('utf-8')
    z['uid'] = f"({z['table']}:{z['row']})"

    ByteLoc += 36 + RGTLen + 6

    temp = []
    for y in range(data_header['RGDFYr'], data_header['RGDLYr'] + 1):
        temp.append((y, struct.unpack('f', data[ByteLoc: ByteLoc + 4])[0]))
        ByteLoc += 4

    y = list(zip(*temp))
    z['data'] = pd.Series(data=y[1], index=y[0])

    my_strings = ['graph_units',
                  'graph_label',
                  'data_type',
                  'sector',
                  'energy_source',
                  'geography',
                  'var_units',
                  'expression']

    z['text'] = {}
    for i in range(len(my_strings)):
        my_len = struct.unpack('h', data[ByteLoc: ByteLoc + 2])[0]
        ByteLoc += 2
        z['text'][my_strings[i]] = data[ByteLoc: ByteLoc + my_len].decode('utf-8')
        ByteLoc += my_len
            
    return z


def process_ran_file_to_dicts(f, logfile):
    """insert docstring here'''
    https://docs.python.org/3/library/struct.html#examples
    """
    logfile.write('\n')

    with open(f, 'rb') as f:
        data = f.read()

    # ---------
    # Main Header
    logfile.write('\n\nMain Header')

    dt = [('RMVer','S4'),
          ('RMLen','i4'),
          ('RSLen','i4'),
          ('RTLen','i4'),
          ('RDLen','i4')]

    logfile.write(f'data format: {dt}')

    d = data[0:20]
    d = np.frombuffer(d, np.dtype(dt))[0]
    header_main = {j[0]: d[i] for i,j in enumerate(dt)}

    logfile.write('header_main: {}'.format(header_main))
    for i in dt:
        j = i[0]
        logfile.write('{}: {}'.format(j, header_main[j]))

    # inferred. note that Python is zero-based
    RMptr = 0  # Python is zero-based
    RSptr = RMptr + header_main['RMLen']
    RTptr = RSptr + header_main['RSLen']
    RDptr = RTptr + header_main['RTLen']
    RGptr = RDptr + header_main['RDLen']

    logfile.write('RMptr: {}'.format(RMptr))
    logfile.write('RSptr: {}'.format(RSptr))
    logfile.write('RTptr: {}'.format(RTptr))
    logfile.write('RDptr: {}'.format(RDptr))
    logfile.write('RGptr: {}'.format(RGptr))
    # ---------

    # ---------
    # Scenario Header
    logfile.write('\n\nScenario Header')

    ByteLoc = RSptr
    logfile.write('ByteLoc: {}'.format(ByteLoc))

    RSFLen = struct.unpack('h', data[RSptr+4:RSptr+6])[0]
    logfile.write('RSFLen: {}'.format(RSFLen))

    RSSLen = struct.unpack('h', data[RSptr+6+RSFLen:RSptr+6+RSFLen+2])[0]
    logfile.write('RSSLen: {}'.format(RSSLen))

    dt = [('RSVer','S4'),
          ('RSFLen','i2'),
          ('RSFile','S'+str(RSFLen)),
          ('RSSLen','i2'),
          ('RSScen','S'+str(RSSLen))]

    logfile.write('data format: {}'.format(dt))

    d = data[ByteLoc: ByteLoc + 8 + RSFLen + RSSLen]
    d = np.frombuffer(d, np.dtype(dt))[0]
    header_scenario = {j[0]: d[i] for i, j in enumerate(dt)}
    # print('Version: {}'.format(header_scenario['RSVer']))

    logfile.write('header_scenario: {}'.format(header_scenario))
    for i in dt:
        j = i[0]
        logfile.write('{}: {}'.format(j, header_scenario[j]))
    # ---------

    # ---------
    # Table Location Header
    logfile.write('\n\nTable Location Header')

    ByteLoc = RTptr
    logfile.write('ByteLoc: {}'.format(ByteLoc))

    logfile.write('The first 2-bytes of the Table Location header indicate the total number of data tables.')
    RTNum = struct.unpack('h', data[ByteLoc:ByteLoc + 2])[0]

    ByteLoc += 2

    dt = [('RTKey','S6'),
          ('RTTRow','i2'),
          ('RTDRow','i2'),
          ('RTDLoc','i4'),
          ('RTILoc', 'i4')]

    logfile.write('Data format per table: {}'.format(dt))

    header_tableloc = []
    for i in range(RTNum):
        d = np.frombuffer(data[ByteLoc:ByteLoc+18],np.dtype(dt))[0]
        temp = {j[0]: d[i] for i, j in enumerate(dt)}
        header_tableloc.append(temp)

        logfile.write(f'Table {i}: {header_tableloc[i]}')

        ByteLoc += 18

    logfile.write(f'Ending ByteLoc (meaningless as long as < RDptr): {ByteLoc}')
    # ---------

    # ---------
    # DataRow Location Header
    logfile.write('\n\nDataRow Location Header')

    ByteLoc = RDptr
    logfile.write('ByteLoc: {}'.format(ByteLoc))

    dt = [('RDKey', 'S16'), ('RDLoc', 'i4')]

    logfile.write(f'data format: {dt}')
    logfile.write('In the following, ByteLoc (plus one) for the -first- mention of a specific table')
    logfile.write(' relates to RTILoc from the Table Location header')

    header_datarowloc = []  # is this LARGE list ever used ???
    for i in range(RTNum):
        for j in range(header_tableloc[i]['RTDRow']):
            d = np.frombuffer(data[ByteLoc:ByteLoc + 20], np.dtype(dt))[0]
            header_datarowloc.append(d)
            logfile.write(f'Table {i}: {d}, ByteLoc: {ByteLoc}')
            ByteLoc += 20

    # print(header_datarowloc)  # about 12,000 characters
    # ---------

    # ---------
    # Read Data Sections
    logfile.write('\n\nData Section')

    t = collections.defaultdict(dict)
    mytables = collections.defaultdict(dict)

    for j in range(RTNum):
        ByteLoc = header_tableloc[j]['RTDLoc'] - 1  # "-1" since Python is zero-based
        logfile.write(f'ByteLoc: {ByteLoc}')
        if j+1 < RTNum:
            XLoc = header_tableloc[j+1]['RTDLoc'] - 1
        else:
            XLoc = header_tableloc[j]['RTDLoc'] * 2

        logfile.write(f'Table: {j}, ByteLoc: {ByteLoc}, XLoc: {XLoc}')

        while (ByteLoc < XLoc) and (ByteLoc < len(data)):
            dt_0 = [('RGType', 'i2'),
                    ('RGSTyp', 'i2'),
                    ('RGLRem', 'i2')]
            d = np.frombuffer(data[ByteLoc: ByteLoc + 6], np.dtype(dt_0))[0]
            logfile.write('d: {}'.format(d))
            data_header = {j[0]: d[i] for i, j in enumerate(dt_0)}
            s = 'data header: {}'.format(data_header)
            logfile.write(s)
            ByteLoc += 6

            logfile.write(f'RGType loop: ByteLoc: {ByteLoc}')

            if data_header['RGType'] == 1:  # main heading
                z = read_datatype_1(data, ByteLoc)
                t[z['RGTKey']]['text_{}'.format(z['RGTTyp'])] = z['RGText'].decode('utf-8')
                t[z['RGTKey']]['tablenum'] = z['RGTNum']
            elif data_header['RGType'] == 2:  # sub-heading
                z = read_datatype_2(data, ByteLoc)
                # TODO: what can we with the data in z for head type 2?
            elif data_header['RGType'] == 3:  # data row
                z = read_datatype_3(data, ByteLoc)
                mytables[z['table']][z['row']] = z
            else:
                s = f"Unknown RGType: {data_header['RGType']}"
                # footnote, maybe?
                #print(s)
                #logfile.write(s)

            ByteLoc += data_header['RGLRem'] # skip to the end of the record

    # give meaningful names to the 'text' keys
    # note: 'text_3' is blank (as of 2018)
    for k in t.keys():
        t[k]['caption'] = t[k]['text_1']
        t[k]['caption_units'] = t[k]['text_2']
        t[k]['caption_sub'] = t[k]['text_4']

    # delete re-named keys
    for k in t.keys():
        for k2 in ['text_1', 'text_2', 'text_3', 'text_4']:
            t[k].pop(k2, None)
       
    return t, mytables


def process_ran_dicts_to_dataframes(t, x):
    temp = {k.decode('utf-8'): {'tablenum': str(t[k]['tablenum']).zfill(3), 
                'caption': t[k]['caption'],
                'caption_sub': t[k]['caption_sub'],
                'caption_units': t[k]['caption_units']} for k in t.keys()}
    df = pd.DataFrame.from_dict(temp, orient='index')
    df.index.name = 'code'
    df = df.reset_index()
    df = df.sort_values(by=['tablenum'])
    df = df.loc[:, ['tablenum', 'code', 'caption', 'caption_sub', 'caption_units']]
    df_tables = df.copy()

    # Row labels
    # we maybe could do this in a dict comprehension, but this is easier to read
    i = -1
    temp = {}
    for s1 in x.keys():
        for s2 in x[s1].keys():
            i += 1
            temp[i] = {}
            temp[i]['code'] = x[s1][s2]['uid']
            temp[i]['tablenum'] = str(x[s1][s2]['tablenum']).zfill(3)
            temp[i]['rownum'] = str(x[s1][s2]['rownum']).zfill(3)
            temp[i]['graph_label'] = x[s1][s2]['text']['graph_label']
            temp[i]['graph_units'] = x[s1][s2]['text']['graph_units']

    df = pd.DataFrame.from_dict(temp, orient='index')
    df = df.sort_values(by=['tablenum', 'rownum'])
    df = df.loc[:, ['tablenum', 'rownum', 'code', 'graph_label', 'graph_units']]
    df_rows = df.copy()

    # Row data
    # maybe could do this in a dict comprehension, but this is easier to read
    mylist = []
    for s1 in x.keys():
        for s2 in x[s1].keys():
            df = x[s1][s2]['data'].loc[range(2010,2051)]
            df = df.to_frame().rename(columns={0: 'level'})
            df.index.name = 'year'
            df = df.reset_index()
            df.loc[:, 'tablenum'] = str(x[s1][s2]['tablenum']).zfill(3)
            df.loc[:, 'rownum'] = str(x[s1][s2]['rownum']).zfill(3)
            mylist.append(df.loc[:, ['tablenum','rownum','year','level']].copy())

    df = pd.concat(mylist)
    df = df.sort_values(by=['tablenum', 'rownum', 'year'])
    df_rowdata = df.copy()

    return df_tables, df_rows, df_rowdata


def read_ran(ranfile, logfilename='ranlog.txt'):
    logfile = open(logfilename, 'w')
    s = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    logfile.write(f'Start: {s}\n')
    t, x = process_ran_file_to_dicts(ranfile, logfile)
    df_tables, df_rows, df_rowdata = process_ran_dicts_to_dataframes(t, x)
    s = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    logfile.write(f'\n\nEnd: {s}')
    logfile.close()

    return df_tables, df_rows, df_rowdata

import os
def main():
    debug = 1
    #ranfile = r"\\nem3\m\ogs\mc6\RAN\ref2020.1121a.RAN"
    # ranfile = 'ref2023.1015a.RAN'
    # ranfile = os.path.join(os.getcwd(),'ref2023.1224a.RAN')
    # ranfile = os.path.join(os.getcwd(),'test.RAN')
    #TODO: Josh to rewrite this line to generate .RAN files for each cycle
    ranfile = os.path.join(os.getcwd(),'ref2024.d042324d_RW.RAN')

    print(f'\nReading: {ranfile}')
    df_tables, df_rows, df_rowdata = read_ran(ranfile)

    if debug > 0:
        print('\n\n\n')
        print('df_tables head and tail')
        print(df_tables.head(10))
        print(df_tables.tail(10))
        print('\n')
        print('df_rows head and tail')
        print(df_rows.head(10))
        print(df_rows.tail(10))
        print('\n')
        print('df_rowdata head and tail')
        print(df_rowdata.head(10))
        print(df_rowdata.tail(10))

    f = 'tables.xlsx'
    df = df_tables.copy()
    df['tablenum'] = df['tablenum'].astype(str).apply(lambda x: x.zfill(3))
    df['tab_name'] = 'T' + df['tablenum']
    df['caption'] = df['tab_name'] + '. ' + df['caption']
    my_cols = ['tab_name','code','caption','caption_sub','caption_units']
    df[my_cols].astype(str).to_excel(f, index=False)

    f = 'rows.xlsx'
    df = df_rows.copy()
    df = df.astype(str)
    df['tablenum'] = df['tablenum'].astype(str).apply(lambda x: x.zfill(3))
    df['tab_name'] = 'T' + df['tablenum']
    df['rownum'] = df['rownum'].astype(str).apply(lambda x: x.zfill(3))
    df['row_name'] = 'R' + df['rownum']
    df['tabrow_name'] = df['tab_name'] + ':' + df['row_name']
    my_cols = ['tabrow_name','code','graph_label','graph_units']
    df[my_cols].astype(str).to_excel(f, index=False)

    f = 'rowdata.xlsx'
    df = df_rowdata.copy()
    df['tablenum'] = df['tablenum'].astype(int)
    df = df.loc[df.tablenum<=139,:]  # 139 is Table 150 in grafnem. We skip regional tables (>139)
    df['tablenum'] = df['tablenum'].astype(str).apply(lambda x: x.zfill(3))
    df['tab_name'] = 'T' + df['tablenum']
    df['rownum'] = df['rownum'].astype(str).apply(lambda x: x.zfill(3))
    df['row_name'] = 'R' + df['rownum']
    df['tabrow_name'] = df['tab_name'] + ':' + df['row_name']    
    my_cols = ['tab_name','tabrow_name','year','level']
    df[my_cols].to_excel(f, index=False)

    return df_tables, df_rows, df_rowdata


if __name__ == '__main__':
    import time

    print('This program can take as long as 5 minutes to execute...')
    start = time.process_time()
    df_tables, df_rows, df_rowdata = main()
    elapsed = time.process_time() - start
    print(f'Elapsed time (sec): {elapsed: .2f}')
